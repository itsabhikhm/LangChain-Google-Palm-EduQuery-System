{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAwjgjhGQUHJ"
      },
      "source": [
        "### Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAy1rxyaNFS1",
        "outputId": "a76b150a-2bbe-4942-8f45-3db21e58ce3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain \\\n",
        "  langchain_community \\\n",
        "  InstructorEmbedding \\\n",
        "  sentence-transformers==2.2.2 \\\n",
        "  langchain-google-genai \\\n",
        "  faiss-cpu \\\n",
        "  pillow --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8blh0qzTQXb4"
      },
      "source": [
        "### Setup API and Load Gemini-Pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jkpBnfGtOMXm"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RX4C7d8eOT6S"
      },
      "outputs": [],
      "source": [
        "api_key = \"YOUR_API_KEY_HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxafdFNCOJOi",
        "outputId": "5a2943d5-f9bf-473f-c080-9e70a9310808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Golden brown, a crispy shell,\n",
            "Spicy bliss, a savory spell.\n",
            "With chutney dipped, a perfect bite,\n",
            "Oh, samosa, my heart's delight! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\",google_api_key=api_key)\n",
        "result = llm.invoke(\"Write a 4 line poem of my love for chai\")\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y26r6E30QPMX"
      },
      "source": [
        "### Create Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IujFINpBO_Nh"
      },
      "outputs": [],
      "source": [
        "# Import the CSV File, Create a Langchain Loader\n",
        "from langchain.document_loaders import CSVLoader\n",
        "loader = CSVLoader(\"/content/codebasics_faqs.csv\",source_column=\"prompt\", encoding=\"latin-1\") # Try loading with Latin-1 encoding\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvCxpV3GQLiM"
      },
      "source": [
        "### Create Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXp3v91lZn8K"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "\n",
        "instructor_embeddings = HuggingFaceInstructEmbeddings()\n",
        "e = instructor_embeddings.embed_query(\"What is your refund policy?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNbkb_bwdtNk"
      },
      "source": [
        "### Creating FASSIS Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZNMfd-dIdcfM"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "faiomd7jd2CP"
      },
      "outputs": [],
      "source": [
        "vectordb = FAISS.from_documents(documents= data,\n",
        "                                embedding = instructor_embeddings) # Creating a Vector DB out of the CSV File using an embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NsFoSYMtjwG_"
      },
      "outputs": [],
      "source": [
        "vectordb.save_local(\"faiss_index\") # We can also save the vector Database Locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GyAjzAYddKF4"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rj-LSdNcgtY"
      },
      "source": [
        "#### Creating a Retriver Object From the Vector Database\n",
        "\n",
        "* The job of this object is, it will take an input\n",
        "* Convert input to embedding vector\n",
        "* Pull the similar vectors from the vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynoA7DJ1xZmm",
        "outputId": "dc3d444a-1e91-4493-9e61-5b0c10a1d885"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}),\n",
              " Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
              " Document(page_content='prompt: Does this bootcamp have lifetime access?\\nresponse: Yes', metadata={'source': 'Does this bootcamp have lifetime access?', 'row': 7}),\n",
              " Document(page_content='prompt: Do we have an EMI option?\\nresponse: No', metadata={'source': 'Do we have an EMI option?', 'row': 13})]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdocs = retriever.invoke(\"Do you have placement support\") # Fetching Relevent Documents/Vectors based on a sentence\n",
        "rdocs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOUSoBXcgkAE"
      },
      "source": [
        "### Making a prompt template and controlling hallucination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "c7ctTsu-grYx"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
        "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
        "If the answer is not found in the context, kindly state \"Sorry, I do not have answer for this question.\" Don't try to make up an answer.\n",
        "\n",
        "CONTEXT: {context}\n",
        "\n",
        "QUESTION: {question}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MMkDChDh0F-"
      },
      "source": [
        "### Make a prompt with the relevant docs using RetrivalQA class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YDBgV1u4dH7q"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(llm = llm,\n",
        "           chain_type = \"stuff\", # There are two types of chain stuff and map-reduce\n",
        "           retriever = retriever,\n",
        "           input_key = \"query\",\n",
        "           return_source_documents = True, # When you get an answer, return source from the csv file\n",
        "           chain_type_kwargs = {\"prompt\" : prompt})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFIqrQC908_b",
        "outputId": "a0468839-5ce6-4a09-96d5-2bc4cf312b38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Do you guys provide intenrship and also do you offer EMI payment',\n",
              " 'result': 'Sorry, I do not have answer for this question. \\n',\n",
              " 'source_documents': [Document(page_content='prompt: Do we have an EMI option?\\nresponse: No', metadata={'source': 'Do we have an EMI option?', 'row': 13}),\n",
              "  Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}),\n",
              "  Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
              "  Document(page_content='prompt: Does this bootcamp have lifetime access?\\nresponse: Yes', metadata={'source': 'Does this bootcamp have lifetime access?', 'row': 7})]}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"Do you guys provide intenrship and also do you offer EMI payment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqn0qygucW8o",
        "outputId": "7504700e-48f4-4b38-d6b3-eb1b89395a20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Do you have javascript course',\n",
              " 'result': \"This document doesn't contain the answer to that question. It only talks about the prerequisites and target audience for a data analytics course or bootcamp. \\n\",\n",
              " 'source_documents': [Document(page_content='prompt: I have never done programming and belong to a non-technical background. Can I take this course?\\nresponse: Yes, this is the perfect course for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in their current job or business using data.', metadata={'source': 'I have never done programming and belong to a non-technical background. Can I take this course?', 'row': 24}),\n",
              "  Document(page_content='prompt: I have never done programming in my life. Can I take this bootcamp?\\nresponse: Yes, this is the perfect bootcamp for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in your current job or business using data.', metadata={'source': 'I have never done programming in my life. Can I take this bootcamp?', 'row': 0}),\n",
              "  Document(page_content='prompt: Is there any prerequisite for taking this bootcamp ?\\nresponse: Our bootcamp is specifically designed for beginners with no prior experience in this field. The only prerequisite is that you need to have a functional laptop with at least 4GB ram, an internet connection, and a thrill to learn data analysis.', metadata={'source': 'Is there any prerequisite for taking this bootcamp ?', 'row': 2}),\n",
              "  Document(page_content='prompt: Is there any prerequisite for taking this course?\\nresponse: The only prerequisite is that you need to have a functional laptop with at least 4GB ram, internet connection and a thrill to learn data analysis.', metadata={'source': 'Is there any prerequisite for taking this course?', 'row': 35})]}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"Do you have javascript course\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efG5q6u9wUo_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
